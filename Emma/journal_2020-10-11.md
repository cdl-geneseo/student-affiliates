# Our Place in Learning **Management** Systems

Since the outbreak of the novel coronavirus, we have relied on Learning Management Systems like Canvas and Blackboard to continue our education digitally. On the surface, this doesn't seem so bad. But we (speaking for students and faculty alike) were never given the option to decline participation in LMSs, partly because of their necessity at the moment, and partly because we were already entrenched in them. Given alarming information about data harvesting and the formation of algorithmic identities, maybe it's time we re-consider our dependence on the LMS model. 

Fact: student and faculty data is being continuously gathered by LMSs. This may seem innocuous at first: why should we care if Canvas is monitoring when and where we logged in and for how long? How could such objective data be used against us? Well, this data may be used as a placeholder for and predicter of our identity. Canvas hints at this data-based identity formation in their privacy policy: 

> To make our Site, Apps, and Services more useful to you, our servers (which may be hosted by a third party service provider) collect information from you, including browser type, operating system, Internet Protocol (IP) address...domain name, and/or a date/time stamp for your visit. We also use cookies and web beacons (as described below) and navigational data like Uniform Resource Locators (URL) to gather information regarding the date and time of your visit and the solutions and information for which you searched and which you viewed. Like most Internet services, we automatically gather this data and store it in log files each time you visit our Site, use our Apps, or access your account on our network. We may link this automatically-collected data to personally identifiable information. (Instructure 2018)

The act of ascribing identity through data collection disenfranchises us as individuals. If the data collected by LMSs yields an inaccurate profile, it can impact our future education and career opportunities, especially if we use (and are used) by LMSs from an early age; right now, LMSs are being used in the K-12 setting more than ever before. Can the data LMSs collect truly reflect who we are as individuals? These algorithmic identities reduce us by glossing over our human complexity, as Mariachi and Quill noted in their article: "The fact that some aspects of learning are easier to measure than others might result in simplistic, surface level elements taking on a more prominent role in determining what counts as success. As a result, higher order, extended, and creative thinking may be undermined by processes that favor formulaic adherence to static rubrics." We have limited control over the algorithmic calculations that prescribe us identities on these platforms. We have even less control over where this information ends up. Recently, Canvas was purchased by a private investment equity firm for two billion dollars, rendering our data more vulnerable than ever: 

> What remains unclear is the fate of the student and faculty data as a result of this pending purchase or any other. Data privacy concerns and questions related to the Instructure acquisition have been outlined in a public letter co-signed by dozens of individuals working at colleges and universities that use the Canvas LMS (Young 2020). The letter references legal scholars who have noted the vulnerability of student data to exploitation in private markets. Russell et al. (2018) have written about the commercial availability of student lists for purchase ‘on the basis of ethnicity, affluence, religion, lifestyle, awkwardness, and even a perceived or predicted need for family planning services’ (i). With no federal privacy laws governing student data brokers, student data can be collected, sold, and bought without any apparent legal protections from widespread exploitation. (Mariachi and Quill 2020)

What remains is our ability to choose, however limited it may be. How can we better participate in and challenge educational decision making? Should we opt-out of LMSs in favor of other open platforms like OpenLab, or work to fix the existing model, if it can be fixed at all? This also depends on who manages the Learning Management System. Will our demands for transparency in LMS algorithms go unheard, or will changes be made? If our data can be sold and bought for profit, perhaps transparency is not in the best interest of current systems. Right now, we should let this awareness inform our future decision making, and remember that we do have a choice to disavow harmful Learning Management Systems. 

---
References: 

Roxana Marachi & Lawrence Quill (2020) The case of Canvas: Longitudinal datafication through learning management systems, Teaching in Higher Education, 25:4, 418-434
